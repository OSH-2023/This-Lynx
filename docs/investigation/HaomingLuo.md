# OSDI前沿技术调研
**PB21030838 罗浩铭**

## MLsys方向



### Achieving μs-scale Preemption for Concurrent GPU-accelerated DNN Inferences

#### 提要
论文关注GPU处理不同时延要求的并发DNN任务时的调度问题，即在满足强实时性任务（Real-Time task）的低时延需求的同时，提高非实时任务（Best-effort task）的吞吐量。


#### 成果与创新点
> idea非常简单，不知道为什么之前没有人做。
> 文章成果思路如下：记强实时性任务（Real-Time task）为RT，非实时任务（Best-effort task）为BE。当RT到来，直接kill掉所有的BE，全力执行RT，在此基础上算力还有余则塞给BE。无RT时，直接并发地执行BE。

- 基于GPU Kernel的幂等性，提出了**reset-based preemption**技术，通过**直接kill**正在执行的非实时任务，实现微秒级的任务抢占
- 同时，本工作还基于对DNN推理任务时延可预测性的观察，提出了**Dynamic Kernel Padding**技术，通过动态地将不同任务的GPU Kernel合并到一起，允许非实时任务利用实时任务的剩余资源与其并行执行，在保证实时任务时延不受干扰的情况下，避免非实时任务饥饿，同时也提高了吞吐量。

#### 结果
测试表明，相比只执行实时任务，REEF可以保证对实时任务的时延干扰小于2%的前提下，提高1.1 ~ 4.3倍吞吐。

#### 详细笔记
原来的GPU任务调度方式：
1. 序列执行。将接到的任务仅仅作为一个队列处理，这样既有低时效的问题，又有低吞吐量的问题（见PPT图示）
2. Block-level Preemption。无并发，接到低时延任务就开始执行它直到把它执行完
3. Multi-Streams。用并发的方式，轮流执行多路任务。高吞吐量，但时延高
<img src="src/已有的GPU任务调度方式.png" width=90%>

#### 附：概念解释
- 幂等性：用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用(a+a+a+.....=a)


#### 大作业可行性分析
- 需要GPU





### Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update

#### 提要
论文关注低延迟的模型更新。



#### 成果与创新点
- Ekko允许模型更新直接从训练集群中发送给全球推理集群中的模型副本，从而避免了高延迟的模型验证和广播过程。为了实现这个想法，Ekko实现了一个高效的点对点模型更新分发协议。这个协议利用了模型更新的稀疏性（即一个大型模型短时间内的更新往往会集中在热点参数），从而使得海量在线模型同步得以实现高吞吐和低延迟。
- 另外，Ekko进一步提供了SLO保护机制：一个优先级模型更新调度器和一个模型状态管理器。这个调度器确保了Ekko在繁忙网络上可以优先发送对于SLO具有重大影响的模型更新。同时，模型状态管理器可以保证有害的模型更新（造成精度下降）可以被快速探测，并且将受影响的模型状态做到实时恢复。

#### 结果
在大型集群测试中，我们发现Ekko比最先进的深度学习推荐系统降低了几个量级的模型更新延迟。


#### 详细笔记
现有的深度学习推荐系统无法满足低延迟的模型更新这种需求。它们往往以离线的方式训练和验证模型，之后将模型从单个训练集群中广播给部署在全球推理集群中的模型副本。这种做法会产生分钟甚至小时级别的模型更新延迟，从而对推荐服务的质量（Service-Level Objectives, SLOs）产生负面影响。

（Ekko 源自腾讯微信内部 WePS 项目，已落地微信生产环境两年，将推荐模型更新延迟从数分钟降到2秒，包括视频号、看一看和订阅号等场景，每天服务超过10亿用户。）

#### 附：概念解释



#### 大作业可行性分析




























