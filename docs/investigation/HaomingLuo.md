# OSDI前沿技术调研
**PB21030838 罗浩铭**

## MLsys方向

### Achieving μs-scale Preemption for Concurrent GPU-accelerated DNN Inferences

#### 提要
论文关注GPU处理不同时延要求的并发DNN任务时的调度问题，即在满足强实时性任务（Real-Time task）的低时延需求的同时，提高非实时任务（Best-effort task）的吞吐量。


#### 成果与创新点
> idea非常简单，不知道为什么之前没有人做。
> 文章成果思路如下：记强实时性任务（Real-Time task）为RT，非实时任务（Best-effort task）为BE。当RT到来，直接kill掉所有的BE，全力执行RT，在此基础上算力还有余则塞给BE。无RT时，直接并发地执行BE。

- 基于GPU Kernel的幂等性，提出了**reset-based preemption**技术，通过**直接kill**正在执行的非实时任务，实现微秒级的任务抢占
- 同时，本工作还基于对DNN推理任务时延可预测性的观察，提出了**Dynamic Kernel Padding**技术，通过动态地将不同任务的GPU Kernel合并到一起，允许非实时任务利用实时任务的剩余资源与其并行执行，在保证实时任务时延不受干扰的情况下，避免非实时任务饥饿，同时也提高了吞吐量。

#### 结果
测试表明，相比只执行实时任务，REEF可以保证对实时任务的时延干扰小于2%的前提下，提高1.1 ~ 4.3倍吞吐。

#### 详细笔记
原来的GPU任务调度方式：
1. 序列执行。将接到的任务仅仅作为一个队列处理，这样既有低时效的问题，又有低吞吐量的问题（见PPT图示）
2. Block-level Preemption。无并发，接到低时延任务就开始执行它直到把它执行完
3. Multi-Streams。用并发的方式，轮流执行多路任务。高吞吐量，但时延高
<img src="src/已有的GPU任务调度方式.png" width=90%>

#### 附：概念解释
- 幂等性：用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用(a+a+a+.....=a)


#### 大作业可行性分析
- 需要GPU





### Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update

#### 提要
论文关注低延迟的模型更新。



#### 成果与创新点
- Ekko允许模型更新直接从训练集群中发送给全球推理集群中的模型副本，从而避免了高延迟的模型验证和广播过程。为了实现这个想法，Ekko实现了一个高效的点对点模型更新分发协议。这个协议利用了模型更新的稀疏性（即一个大型模型短时间内的更新往往会集中在热点参数），从而使得海量在线模型同步得以实现高吞吐和低延迟。
- 另外，Ekko进一步提供了SLO保护机制：一个优先级模型更新调度器和一个模型状态管理器。这个调度器确保了Ekko在繁忙网络上可以优先发送对于SLO具有重大影响的模型更新。同时，模型状态管理器可以保证有害的模型更新（造成精度下降）可以被快速探测，并且将受影响的模型状态做到实时恢复。

#### 结果
在大型集群测试中，我们发现Ekko比最先进的深度学习推荐系统降低了几个量级的模型更新延迟。


#### 详细笔记
现有的深度学习推荐系统无法满足低延迟的模型更新这种需求。它们往往以离线的方式训练和验证模型，之后将模型从单个训练集群中广播给部署在全球推理集群中的模型副本。这种做法会产生分钟甚至小时级别的模型更新延迟，从而对推荐服务的质量（Service-Level Objectives, SLOs）产生负面影响。

（Ekko 源自腾讯微信内部 WePS 项目，已落地微信生产环境两年，将推荐模型更新延迟从数分钟降到2秒，包括视频号、看一看和订阅号等场景，每天服务超过10亿用户。）

#### 附：概念解释



#### 大作业可行性分析



## 分布式系统
### 一致性算法


##　数据密集型应用系统设计读书笔记
要搞清楚要解决的问题是什么，具体的技术手段可以是怎样的
以下的调研将分主题展开，各主题有宏观有微观。

### 总览
当今许多新型应用都属于数据密集型，而不是计算密集型，对于这些类型的应用，CPU的处理能力不是瓶颈，关键在于数据量、数据复杂度及数据的快速多变性。

#### 场景


##### 可靠性
- 系统局部失效时，保障数据正确性与完整性
- 系统降级





##### 可扩展
- 系统增加




##### 可维护
- 友好的API




#### 总体结构
它通常包含以下部分：数据库、高速缓存、索引、流式处理、批处理，









### 分布式数据系统
#### 场景
##### 总的场景
- 负载过大，需要分散到各个机器上
- 需要多台机器提供冗余
- 在全球范围内部署服务，以方便用户从最近的数据中心获取服务（可忽略）



#### 总体结构
无共享结构为主流，我们将主要使用无共享结构，即各主机之间只通过传统网络连接，相对于共享硬件的有共享结构。



### 复制
#### 场景
> 这里的场景主要指复制技术具体遇到的问题

- 数据处于不断变化之中，常规复制会导致不同节点之上呈现不同时间点的数据
- 异步复制，原主节点的所有数据未分发完时掉线，此时新主节点并未受到所有的写请求；若它再上线，可能让新的主节点收到冲突的写请求
- 如果在数据库之外有其他系统依赖于数据库的内容并在一起协同使用，丢弃数据的方案就特別危险。例如，在GitHub的一个事故中, 某个数据并非完全同步的MySQL从节点被提升为主副本，数据库使用了自增计数器将主键分配给新创建的行，但是因为新的主节点计数器落后于原主节点（即二者并非完全同步） ，它重新使用了已被原主节点分配出去的某些主键，而恰好这些主键已被外部Redis所引用，结果出现MySQL和Redis之间的不一致，最后导致了某些私有数据被错误地泄露给了其他用户。
- 两个节点都自认为是主节点
- 如何设置合适的超时时间来检测主节点失效？太长则恢复时间久，太短则容易将正常情况误判为掉线

最严苛的有：
- 由于软件BUG造成的无提示数据损坏



#### 具体技术
##### 处理节点失效
从节点失效：追赶式恢复，从节点可以得知故障前处理的最后一笔事务，然后连接到主节点，并请求那次事务之后的所有数据变更，将其应用到本地以追赶主节点

主节点失效：节点切换，确认主节点失效，选举新的主节点，重新配置系统令新主节点生效








##### 复制日志的实现
###### 基于语句的复制
复制每个操作语句。
问题是：
- 任何调用非确定性函数，如NOW()获取当前时间，或者RAND()获取随机数的操作，可能产生不同结果（可将其替换为执行后结果再分发，但存在太多边界条件需要考虑）
- 副本必须完全按照顺序执行，这对并发执行限制很大
- 有副作用的语句可能在每个副本上产生副作用

###### 基于预写日志(WAL)
对数据库写入的字节序列都被加进日志，其粒度足以让从节点与主节点完全同步
其缺点是：
- 日志描述的数据结果非常底层，比如哪些磁盘块的哪些字节发生改变，甚至主从节点使用不同版本的存储程序都不行（这使得不能热更新应用，必须停机）

###### 基于行的逻辑日志复制
复制日志与存储引擎采用不同格式，这时复制日志称为逻辑日志。它与存储底层逻辑剥离，可支持不同版本甚至不同应用间的复制，信息以行作为单位（MYSQL的binlog基于该方式）

###### 基于触发器的复制
数据变更将触发一段指定代码的执行，灵活度很高，不过复制开销更大





#### 复制滞后问题
##### 要保证的一致性
写后读一致性：保证用户总能看到自己提交的新数据

单调读：用户在某个时间点读到数据之后，不能再读到比该时间点更早的数据

前缀一致读：保证数据的因果关系，如总是先读取问题再读取回答
























