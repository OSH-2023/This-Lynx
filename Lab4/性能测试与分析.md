# 性能测试与分析

## 测试所用benchmark任务
随着深度学习近年来的繁荣发展，神经网络训练及部署已经成为当前Ray等分布式计算系统最重要的应用场景之一。
因此，此次实验中，我们选择了神经网络部署的场景，来编写测试程序。
假定我们有一个输入大小为784，输出大小为10，中间两隐含层大小为500与300的全连接层神经网络（约55万参数），其参数已经训练完毕，即将部署到生产场景中。我们将其部署到Ray上，用以处理一批总量为20000的输入数据。
我们选择的任务可用代码描述如下（以下代码经过简化）：
```python
ray.init(dashboard_host="0.0.0.0")

size=[784,500,300,10]
nn=NN.remote(size) #NN为一神经网络类

# Launch four parallel square tasks.
futures = [nn.forward.remote(np.random.random(784)) for _ in range(20000)]

# Retrieve results.
print("Total number of results:",len(ray.get(futures)))
print("First 10 results:", ray.get(futures)[0:10])
```
我们将此程序作为Ray的测试样例，基于此进行部署、优化、测试。

（官网上有不少测试样例，同样可用于测试，有需要者可访问：https://docs.ray.io/en/latest/ray-air/benchmarks.html）


## 测试性能指标

- 资源使用率（如CPU、内存、GPU使用率）
- 吞吐量（单位时间处理的任务数）
- 单任务响应时间（每个任务从提交到完成的平均时间）
- 任务运行时调用的Actor数量（反映并行性）
- I/O与网络负载（I/O与网络的吞吐量大小）
- 任务执行成功率（没有特殊情况应该保证绝对地为100%）

由于吞吐量是分布式计算框架最重要的性能指标之一，我们将毫无疑问地选择它作为测试指标；同时，资源使用率是评价Ray硬件调度有效性的重要指标，而由于本任务为CPU密集型（未在GPU上计算），其它硬件负载较小，运行任务时较平时利用率无明显变化，我们将选择CPU利用率作为性能指标。
综上所述，我们选择的性能测试指标为吞吐量和CPU使用率。
我们的吞吐量计算方式为

## 性能测试结果与分析
### 单机部署
对优化前的程序进行测试，任务参数为：任务量20000，未分组，测得吞吐量如下：
| 组别  | 用时/s | 吞吐量/任务数每秒 |
| :---: | :----: | :---------------: |
|   1   | 35.64  |       561.2       |
|   2   | 35.44  |       564.3       |
|   3   | 34.77  |       575.2       |
|   4   | 35.36  |       565.6       |
|   5   | 34.02  |       587.9       |
| 平均  | 35.05  |       570.8       |
为测得CPU使用率，我们应加大任务量至80000，以使Ray稳定运行一段时间（约2分钟），获得稳定的CPU使用率数据。
测得有效数据点如下：
<img src="src/test%20original%20cpu%20uti%20table.png" width="50%">
其图像如下：
<img src="src/test%20new%20cpu%20uti%20plot.png" width="100%">
则CPU使用率平均为13.6%


### 单机优化
我们注意到，一个类只能启动一个Actor，所以我们为神经网络类套了一层壳，写成一个新的类Actor。这样，我们可以同时启动多个Actor，并行运算，大幅提高性能，这些Actor使用同样的神经网络及参数。

| 组别  | 用时/s | 吞吐量/任务数每秒 |
| :---: | :----: | :---------------: |
|   1   |  6.12  |      3268.0       |
|   2   |  6.22  |      3215.4       |
|   3   |  6.18  |      3236.2       |
|   4   |  6.10  |      3278.7       |
|   5   |  6.19  |      3231.0       |
| 平均  |  6.16  |      3245.9       |

为测得CPU使用率，我们应加大任务量至500000，以使Ray稳定运行一段时间（约2分钟），获得稳定的CPU使用率数据。
测得有效数据点如下：
<img src="src/test%20new%20cpu%20uti%20table.png" width="50%">
其图像如下：
<img src="src/test%20new%20cpu%20uti%20plot.png" width="100%">
则CPU使用率平均为79.0%，维持在一个较高的水平。



### 分布式部署
我们以20000任务量，每组10个任务（函数参数规模过大时，会导致Ray报错，无法正常运行，故此处只能设为每组10个任务）
| 组别  | 用时/s | 吞吐量/任务数每秒 |
| :---: | :----: | :---------------: |
|   1   |  9.62  |      2079.0       |
|   2   | 11.06  |      1808.3       |
|   3   | 13.15  |      1520.9       |
|   4   |  8.68  |      2304.1       |
|   5   |  9.61  |      2081.2       |
| 平均  | 10.42  |      1958.7       |
可以看到，分布式条件下，性能的波动明显变大，同时

为测得CPU使用率，我们应加大任务量至250000，以使Ray稳定运行一段时间（约2分钟），获得稳定的CPU使用率数据。
测得有效数据点如下：
<img src="src/test%20dis%20cpu%20uti%20table.png" width="80%">
其图像如下：
<img src="src/test%20dis%20cpu%20uti%20plot.png" width="100%">
则CPU使用率平均为31.0%。


## 附：测试所用benchmark代码（优化后）
```python
import ray
import numpy as np
import time
import sys
import copy

def relu(x):
    if x > 0:
        return x
    else:
        return 0.0


class NN:  # neural network
    def __init__(self, size):
        # 搭建神经网络
        self.weight = []  # 神经网络权重
        # self.sum_adjust_weight=[]#神经网络反向传播中对权重求导所得导数
        # self.layer=[]#神经网络输入层、各隐含层和输出层
        self.bias = []  # 神经网络各层偏置
        # self.sum_adjust_bias=[]#神经网络反向传播中对偏置求导所得导数
        self.size = size  # 神经网络各层神经元数量

        self.total_loss = 0.0  # 用来计算神经网络损失函数
        # self.total_correct=0
        for i in range(len(size)):
            # self.layer.append(np.zeros(size[i],dtype=np.float16))
            self.bias.append(np.zeros(size[i], dtype=np.float16))
        for i in range(len(size) - 1):
            self.weight.append(
                np.random.normal(
                    0, 2.0 / np.sqrt(size[i] + size[i + 1]), size=(size[i], size[i + 1])
                )
            )  # Xavier初始化
    def set_weight_and_bias(self, weight, bias): #复制神经网络参数，请保证神经网络架构不变
        self.weight=weight
        self.bias=bias

    def get_weight_and_bias(self): #获取神经网络参数
        return self.weight, self.bias

    def forward(self, layer_inputs):  # 由输入求神经网络输出结果
        result = []
        for layer_input in layer_inputs:
            x = np.array(layer_input)
            for i in range(1, len(size)):
                x = x @ self.weight[i - 1]
                for j in range(len(x)):
                    x[j] = relu(x[j] + self.bias[i][j])
            result.append(x)

        return result

size = [784, 500, 300, 10]
nn = NN(size)

@ray.remote
class Actor:
    def __init__(self):
        self.nn=nn
    
    def forward(self, layer_inputs):
        return self.nn.forward(layer_inputs)


if __name__ == "__main__":
    ray.init(address='auto', dashboard_host="0.0.0.0")

    if len(sys.argv) < 2:
        task_num = 20000
    else:
        task_num = int(sys.argv[1])

    if len(sys.argv) < 3:
        batch_size = 10 #表示每批任务的task数
    else:
        batch_size = int(sys.argv[2])

    start = time.time()

    actor_num=10
    nn_actor=[Actor.remote() for _ in range(actor_num)]


    # Launch four parallel square tasks.
    #batch_size必须被task_num整除
    futures = []
    for i in range(task_num // batch_size):
        nn_input=[np.random.random(784) for _ in range(int(batch_size))]
        #nn_input_ref=ray.put(nn_input)
        futures.append(
            nn_actor[i % actor_num].forward.remote(nn_input)
        )

    # Retrieve results.
    results = ray.get(futures)
    print("Total number of results:", sum([len(result) for result in results]))
    print("First 10 results:", results[0][0:10])

    print("Duration: ", time.time() - start)

```





